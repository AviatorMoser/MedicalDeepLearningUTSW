{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pre-Trained Networks on Small Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal: Classify Types of X-Ray: Chest or Abdomen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the previous example, we trained a network from scratch using 60,000 images. Having 60,000 images with classes predefined is convenient, but not necessarily always available for every application. Sometimes, only small datasets are available. For instance, in this example we only have 65 training images available, three orders of magnitude less than the MNIST example and an insufficient number to train a network from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p float=\"left\">\n",
    "    <img src=\"Open_I_abd_vs_CXRs/TRAIN/openI_CXR/80_IM-2333-3001_invert.png\" width=\"300\" />\n",
    "    <img src=\"Open_I_abd_vs_CXRs/TRAIN/openI_abd_xray/openI_6.png\" width=\"300\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 299, 299               # dimensions of our input -- our model only accepts 299 x 299\n",
    "\n",
    "# location of training and test datasets\n",
    "train_data_dir = 'Open_I_abd_vs_CXRs/TRAIN'    #location of training data\n",
    "validation_data_dir = 'Open_I_abd_vs_CXRs/VAL' #location of validation data\n",
    "\n",
    "nb_train_samples = 65                          # number of samples used for determining the samples_per_epoch\n",
    "nb_validation_samples = 10                     # number of samples used for validating (i.e., testing during training)\n",
    "epochs = 15\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data augmentation to generate more variability and reduce overfitting\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,            # normalizing\n",
    "        shear_range=0.2,      \n",
    "        zoom_range=0.2,    \n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True)  \n",
    "\n",
    "# no need to augment validation except for normalization\n",
    "val_datagen = ImageDataGenerator(\n",
    "         rescale=1./255)       # normalize pixel values to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loaders for training and test sets\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unlike previous exercises, we will not build and train a model from scratch\n",
    "# There just simply isn't enough data!\n",
    "\n",
    "# We could instead train on top of a pre-trained network and slightly tweak it to learn how to recognize our images.\n",
    "# This is like teaching an expert piano player a new song.\n",
    "# The work of past years of training has already been done.\n",
    "\n",
    "# Let's use the InceptionV3 network that has been pretrained on millions of images.\n",
    "# Instead of using it's top layer which is used for its final classification of several other classes\n",
    "# we'll instead remove it and add a shallow network on top to predict only two final classes.\n",
    "\n",
    "base_model = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The new top of our InceptionV3 pre-trained model.\n",
    "\n",
    "model_top = Sequential()\n",
    "model_top.add(GlobalAveragePooling2D(input_shape=base_model.output_shape[1:], data_format=None)),  \n",
    "model_top.add(Dense(256, activation='relu'))\n",
    "model_top.add(Dropout(0.5))\n",
    "model_top.add(Dense(1, activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We now put the new top onto the network\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=model_top(base_model.output))\n",
    "\n",
    "# Our optimizer uses Adam once more, but our loss function is calculated using binary cross-entropy \n",
    "# because we only have two outputs to consider\n",
    "\n",
    "# Note the small initial learning rate\n",
    "# This is on purpose because we don't want to disturb the weights of the network too much\n",
    "# Remember, our musician is learning a new song -- not a whole other instrument!\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08,decay=0.0), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the model\n",
    "\n",
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=nb_train_samples // batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training stats\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'], 'orange', label='Training accuracy')\n",
    "plt.plot(history.history['val_acc'], 'blue', label='Validation accuracy')\n",
    "plt.plot(history.history['loss'], 'red', label='Training loss')\n",
    "plt.plot(history.history['val_loss'], 'green', label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "img_path= 'Open_I_abd_vs_CXRs/TEST/chest2.png' #change to location of chest x-ray\n",
    "img_path2= 'Open_I_abd_vs_CXRs/TEST/abd2.png'  #change to location of abd x-ray\n",
    "img = image.load_img(img_path, target_size=(img_width, img_height))\n",
    "img2 = image.load_img(img_path2, target_size=(img_width, img_height))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "img = image.img_to_array(img)\n",
    "x = np.expand_dims(img, axis=0) * 1./255\n",
    "score = model.predict(x)\n",
    "print('Predicted:', score, 'Chest X-ray' if score < 0.5 else 'Abd X-ray')\n",
    "\n",
    "plt.imshow(img2)\n",
    "plt.show()\n",
    "\n",
    "img2 = image.img_to_array(img2)\n",
    "x = np.expand_dims(img2, axis=0) * 1./255\n",
    "score2 = model.predict(x)\n",
    "print('Predicted:', score2, 'Chest X-ray' if score2 < 0.5 else 'Abd X-ray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow (GPU)",
   "language": "python",
   "name": "py3.6-tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
